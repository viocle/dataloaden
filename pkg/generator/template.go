package generator

import "text/template"

var tpl = template.Must(template.New("generated").
	Funcs(template.FuncMap{
		"lcFirst":                 lcFirst,
		"loadThunkMissReturnType": LoadThunkMissReturnType,
		"LoadThunkMarshalType":    LoadThunkMarshalType,
		"LoadAllMarshalType":      LoadAllMarshalType,
		"ToRedisKey":              ToRedisKey,
	}).
	Parse(`
// Code generated by github.com/viocle/dataloaden, DO NOT EDIT.

package {{.Package}}

import (
	"context"
	"encoding/json"
	"strconv"
    "sync"
    "time"

    {{if .KeyType.ImportPath}}"{{.KeyType.ImportPath}}"{{end}}
    {{if .ValType.ImportPath}}"{{.ValType.ImportPath}}"{{end}}
)

const (
	{{.Name}}CacheKeyPrefix = "{DataLoader{{.Name}}}:"
)

var (
	Err{{.Name}}GetManyLength = errors.New("redis error, invalid length returned from GetManyFunc")
)

// {{.Name}}Config captures the config to create a new {{.Name}}
type {{.Name}}Config struct {
	// Fetch is a method that provides the data for the loader
	Fetch func(keys []{{.KeyType.String}}) ([]{{.ValType.String}}, []error)

	// Wait is how long to wait before sending a batch
	Wait time.Duration

	// MaxBatch will limit the maximum number of keys to send in one batch, 0 = no limit
	MaxBatch int

	{{ if not .DisableCacheExpiration }}
	// ExpireAfter determines how long until cached items expire. Set to 0 to disable expiration
	ExpireAfter time.Duration

	{{ end }}
	// HookExternalCacheGet is a method that provides the ability to lookup a key in an external cache with an external hook.
	// This replaces the use of the internal cache. 
	// If the key is found in the external cache, the value should be returned along with true. 
	// If the key is not found in the external cache, an empty/nil value should be returned along with false.
	// Both HookExternalCacheGet, HookExternalCacheSet, HookExternalCacheDelete, and HookExternalCacheClearAll should be set if using an external cache.
	HookExternalCacheGet func(key {{.KeyType.String}}) ({{.ValType.String}}, bool)

	// HookExternalCacheSet is a method that provides the ability to set a key in an external cache with an external hook.
	// This replaces the use of the internal cache.
	HookExternalCacheSet func(key {{.KeyType.String}}, value {{.ValType.String}}) error

	// HookBeforeFetch is a method that provides the ability to delete/clear a key in an external cache with an external hook.
	// This replaces the use of the internal cache.
	HookExternalCacheDelete func(key {{.KeyType.String}}) error

	// HookExternalCacheClearAll is a method that provides the ability to clear all keys in an external cache with an external hook.
	HookExternalCacheClearAll func() error

	// HookBeforeFetch is called right before a fetch is performed
	HookBeforeFetch func(keys []{{.KeyType.String}}, loaderName string)

	// HookAfterFetch is called right after a fetch is performed
	HookAfterFetch func(keys []{{.KeyType.String}}, loaderName string)

	// HookAfterSet is called after a value is set in the cache
	HookAfterSet func(key {{.KeyType.String}}, value {{.ValType.String}})

	// HookAfterPrime is called after a value is primed in the cache using Prime, ForcePrime, or PrimeMany.
	HookAfterPrime func(key {{.KeyType.String}}, value {{.ValType.String}})

	// HookAfterPrimeMany is called after values are primed in the cache using PrimeMany. If not set then HookAfterPrime will be used if set.
	HookAfterPrimeMany func(keys []{{.KeyType.String}}, values []{{.ValType.String}})

	// HookAfterClear is called after a value is cleared from the cache
	HookAfterClear func(key {{.KeyType.String}})

	// HookAfterClearAll is called after all values are cleared from the cache
	HookAfterClearAll func()

	// HookAfterClearAllPrefix is called after all values are cleared from the cache
	HookAfterClearAllPrefix func(prefix string)
	
	// HookAfterExpired is called after a value is cleared in the cache due to expiration
	HookAfterExpired func(key {{.KeyType.String}})

	// RedisConfig is used to configure a {{.Name}} backed by Redis, disabling the internal cache.
	RedisConfig *{{.Name}}RedisConfig
}

{{ if not .DisableCacheExpiration }}
// {{.Name}}CacheItem defines a cache item when using dataloader cache expiration where expireAfter > 0 
type {{.Name}}CacheItem struct {
	// Expires contains the time this CacheItem expires
	Expires int64

	// Value contains the cached {{.ValType.String}}
	Value {{.ValType.String}}
}

// expired returns true if the cache item has expired
func (c *{{.Name}}CacheItem) expired(now int64) bool {
	return c.Expires < now
}

{{ end }}
// New{{.Name}} creates a new {{.Name}} given a fetch, wait, and maxBatch
func New{{.Name}}(config {{.Name}}Config) *{{.Name}} {
	l := &{{.Name}}{
		fetch: config.Fetch,
		wait: config.Wait,
		maxBatch: config.MaxBatch,{{ if not .DisableCacheExpiration }}
		expireAfter:config.ExpireAfter.Nanoseconds(),{{ end }}
		hookExternalCacheGet: config.HookExternalCacheGet,
		hookExternalCacheSet: config.HookExternalCacheSet,
		hookExternalCacheDelete: config.HookExternalCacheDelete,
		hookExternalCacheClearAll: config.HookExternalCacheClearAll,
		hookBeforeFetch: config.HookBeforeFetch,
		hookAfterFetch: config.HookAfterFetch,
		hookAfterSet: config.HookAfterSet,
		hookAfterPrime: config.HookAfterPrime,
		hookAfterPrimeMany: config.HookAfterPrimeMany,
		hookAfterClear: config.HookAfterClear,
		hookAfterClearAll: config.HookAfterClearAll,
		hookAfterClearAllPrefix: config.HookAfterClearAllPrefix,
		hookAfterExpired:  config.HookAfterExpired,
		redisConfig: config.RedisConfig,
	}
	if config.RedisConfig != nil {
		// validate we have all the required Redis functions. If not, force disable Redis
		if l.redisConfig.GetFunc != nil && l.redisConfig.SetFunc != nil && l.redisConfig.DeleteFunc != nil {
			// all required Redis functions are present, enable Redis
			l.redisConfig = &{{.Name}}RedisConfig{
				SetTTL: config.RedisConfig.SetTTL, // optional
				GetFunc: config.RedisConfig.GetFunc, // (GET)
				GetManyFunc: config.RedisConfig.GetManyFunc, // (MGET) optional, but recommended for LoadAll performance
				SetFunc: config.RedisConfig.SetFunc, // (SET)
				SetManyFunc: config.RedisConfig.SetManyFunc, // (SET/MSET) optional, but recommended for PrimeMany performance. Suggested to use pipeline or MSET
				DeleteFunc: config.RedisConfig.DeleteFunc, // (DEL)
				DeleteManyFunc: config.RedisConfig.DeleteManyFunc, // (DEL) optional, but recommended for ClearAll performance
				GetKeysFunc: config.RedisConfig.GetKeysFunc, // optional, but recommended for ClearAll support
				ObjMarshal: config.RedisConfig.ObjMarshal, // optional
				ObjUnmarshal: config.RedisConfig.ObjUnmarshal, // optional
				KeyToStringFunc: config.RedisConfig.KeyToStringFunc, // optional, but recommended for complex types that need to be serialized
			}
			if l.redisConfig.ObjMarshal == nil || l.redisConfig.ObjUnmarshal == nil {
				// missing ObjMarshal or ObjUnmarshal, force use of json package
				l.redisConfig.ObjMarshal = json.Marshal
				l.redisConfig.ObjUnmarshal = json.Unmarshal
			}
			// set batchResultSet to just call the SetFunc directly, no locks needed
			l.batchResultSet = func(key {{.KeyType.String}}, value {{.ValType.String}}) {
				l.redisConfig.SetFunc(context.Background(), {{.Name}}CacheKeyPrefix+{{ToRedisKey .KeyType.String }}, value, l.redisConfig.SetTTL)
			}
			if l.redisConfig.KeyToStringFunc == nil {
				l.redisConfig.KeyToStringFunc = l.Marshal{{.Name}}ToString
			}
		}
	}
	if l.redisConfig == nil {
		// set the default batchResultSet
		l.batchResultSet = func(key {{.KeyType.String}}, value {{.ValType.String}}) {
			l.mu.Lock()
			l.unsafeSet(key, value)
			l.mu.Unlock()
		}
	}
	l.batchPool = sync.Pool{
		New: func() interface{} {
			return l.createNewBatch()
		},
	}
	return l
}

// {{.Name}}RedisConfig is used to configure a {{.Name}} backed by Redis. GetFunc, SetFunc, and DeleteFunc are required if using Redis. If any function is not provided, Redis will be disabled and internal caching will be used.
type {{.Name}}RedisConfig struct {
	// SetTTL is the TTL (Time To Live) for a key to live in Redis on set. If nil, no TTL will be set.
	SetTTL *time.Duration

	// GetFunc should get a value from Redis given a key and return the raw string value.
	GetFunc func(ctx context.Context, key string) (string, error)

	// GetManyFunc should get one or more values from Redis given a set of keys and return the raw string values, errors the size of keys with non nil values for keys not found, and an error if any other error occurred running the command
	// If not set then GetFunc will be used instead, but will be called one at a time for each key
	GetManyFunc func(ctx context.Context, keys []string) ([]string, []error, error)

	// SetFunc should set a value in Redis given a key and value with an optional ttl (Time To Live)
	SetFunc func(ctx context.Context, key string, value interface{}, ttl *time.Duration) error

	// SetManyFunc should set one or more values in Redis given a set of keys and values with an optional ttl (Time To Live)
	// If not set then SetFunc will be used instead, but will be called one at a time for each key. To implement, look at using a pipeline or MSET
	SetManyFunc func(ctx context.Context,  keys []string, values []interface{}, ttl *time.Duration) ([]error, error)

	// DeleteFunc should delete a value in Redis given a key
	DeleteFunc func(ctx context.Context, key string) error

	// DeleteManyFunc should delete one or more values in Redis given a set of keys
	DeleteManyFunc func(ctx context.Context, key []string) error

	// GetKeysFunc should return all keys in Redis matching the given pattern. If not set then ClearAll() for this dataloader will not be supported.
	GetKeysFunc func(ctx context.Context, pattern string) ([]string, error)

	// ObjMarshal provides you the ability to specify your own encoding package. If not set, the default encoding/json package will be used.
	ObjMarshal func(any) ([]byte, error)

	// ObjUnmarshaler provides you the ability to specify your own encoding package. If not set, the default encoding/json package will be used.
	ObjUnmarshal func([]byte, any) error

	// HookAfterObjUnmarshal is a method that provides the ability to run a function after an object is unmarshaled. This is useful for setting up any object state after unmarshaling or logging.
	HookAfterObjUnmarshal func({{.ValType.String}}) {{.ValType.String}}

	// KeyToStringFunc provides you the ability to specify your own function to convert a key to a string, which will be used instead of serialization.
	// This is only used for non standard types that need to be serialized. If not set, the ObjMarshal function (user defined or default) will be used to serialize a key into a string value
	// Example: If you have a struct with a String() function that returns a string representation of the struct, you can set this function to that function.
	//
	// type MyStruct struct {
	//     ID string
	//     OrgID string
	// }
	// ...
	// {{.Name}}RedisConfig{
	//		KeyToStringFunc = func(key {{.KeyType.String}}) string { return m.ID + ":" + m.OrgID }
	// }
	// ...
	// Or if your key type has a String() function that returns a string representation of the key, you can set this function like this:
	// {{.Name}}RedisConfig{
	//		KeyToStringFunc = func(key {{.KeyType.String}}) string { return key.String() }
	// }
	KeyToStringFunc func(key {{.KeyType.String}}) string
}

// {{.Name}} batches and caches requests          
type {{.Name}} struct {
	// this method provides the data for the loader
	fetch func(keys []{{.KeyType.String}}) ([]{{.ValType.String}}, []error)

	// optional Redis configuration
	redisConfig *{{.Name}}RedisConfig

	// lazily created cache
	{{ if not .DisableCacheExpiration }}
	cacheExpire map[{{.KeyType.String}}]*{{.Name}}CacheItem
	{{ end }}
	cache map[{{.KeyType.String}}]{{.ValType.String}}

	// the current batch. keys will continue to be collected until timeout is hit,
	// then everything will be sent to the fetch method and out to the listeners
	batch *{{.Name|lcFirst}}Batch
	
	// batchResultSet sets the batch result
	batchResultSet func({{.KeyType.String}}, {{.ValType.String}})

	// how long to done before sending a batch
	wait time.Duration

	// this will limit the maximum number of keys to send in one batch, 0 = no limit
	maxBatch int

	{{ if not .DisableCacheExpiration }}
	// the amount of nanoseconds a cache item should remain valid. This will determine if cache expiration will be used, 0 = no expiration
	expireAfter int64

	{{ end }}
	// mutex to prevent races
	mu sync.Mutex

	// hookExternalCacheGet is a method that provides the ability to lookup a key in an external cache with an external hook. 
	// If the key is found in the external cache, the value should be returned along with true. 
	// If the key is not found in the external cache, an empty/nil value should be returned along with false.
	hookExternalCacheGet func(key {{.KeyType.String}}) ({{.ValType.String}}, bool)
	
	// hookExternalCacheSet is a method that provides the ability to set a key in an external cache with an external hook.
	// This replaces the use of the internal cache.
	hookExternalCacheSet func(key {{.KeyType.String}}, value {{.ValType.String}}) error

	// hookBeforeFetch is a method that provides the ability to delete/clear a key in an external cache with an external hook.
	// This replaces the use of the internal cache.
	hookExternalCacheDelete func(key {{.KeyType.String}}) error

	// hookExternalCacheClearAll is a method that provides the ability to clear all keys in an external cache with an external hook.
	hookExternalCacheClearAll func() error

	// hookBeforeFetch is called right before a fetch is performed
	hookBeforeFetch func(keys []{{.KeyType.String}}, loaderName string)

	// hookAfterFetch is called right after a fetch is performed
	hookAfterFetch func(keys []{{.KeyType.String}}, loaderName string)

	// hookAfterSet is called after a value is set in the cache
	hookAfterSet func(key {{.KeyType.String}}, value {{.ValType.String}})

	// hookAfterPrime is called after a value is primed in the cache using Prime, ForcePrime, or PrimeMany
	hookAfterPrime func(key {{.KeyType.String}}, value {{.ValType.String}})

	// hookAfterPrimeMany is called after values are primed in the cache using PrimeMany. If not set then hookAfterPrime will be used if set.
	hookAfterPrimeMany func(keys []{{.KeyType.String}}, values []{{.ValType.String}})

	// hookAfterClear is called after a value is cleared from the cache
	hookAfterClear func(key {{.KeyType.String}})

	// hookAfterClearAll is called after all values are cleared from the cache
	hookAfterClearAll func()
	
	// HookAfterClearAllPrefix is called after all values are cleared from the cache
	hookAfterClearAllPrefix func(prefix string)

	// hookAfterExpired is called after a value is cleared in the cache due to expiration
	hookAfterExpired func(key {{.KeyType.String}})

	// pool of batches
	batchPool sync.Pool
}

type {{.Name|lcFirst}}Batch struct {
	loader *{{.Name}}
	now     int64
	done    chan struct{}
	keysMap map[{{.KeyType}}]int
	keys    []{{.KeyType}}
	data    []{{.ValType.String}}
	errors   []error
	closing bool
	lock sync.Mutex
	reqCount int
	checkedIn int
}

// Load a {{.ValType.Name}} by key, batching and caching will be applied automatically
func (l *{{.Name}}) Load(key {{.KeyType.String}}) ({{.ValType.String}}, error) {
	v, f := l.LoadThunk(key)
	if f != nil {
		return f()
	}
	return v, nil
}

// unsafeBatchSet creates a new batch if one does not exist, otherwise it will reuse the existing batch
func (l *{{.Name}}) unsafeBatchSet() {
	if l.batch == nil {
		b := l.batchPool.Get().(*{{.Name|lcFirst}}Batch)
		// create new batch re-using our keysMap and keys fields
		l.batch = &{{.Name|lcFirst}}Batch{loader: l, now: 0, done: make(chan struct{}), keysMap: b.keysMap, keys: b.keys[:0], data: nil, errors: nil, reqCount: 0, checkedIn: 0, lock: sync.Mutex{}}
	} else if l.batch.now == 0 {
		// have a batch but first use, set the start time
		l.batch.now = time.Now().UnixNano()
	}
}

// createNewBatch creates a new batch
func (l *{{.Name}}) createNewBatch() *{{.Name|lcFirst}}Batch {
	return &{{.Name|lcFirst}}Batch{
		loader: l,
		now: 0, 
		done: make(chan struct{}), 
		keysMap: make(map[{{.KeyType.String}}]int, l.maxBatch), 
		keys: make([]{{.KeyType.String}}, 0, l.maxBatch), 
		data: nil, 
		errors: nil,
		lock: sync.Mutex{},
		reqCount: 0,
		checkedIn: 0,
	}
}

// LoadThunk returns a function that when called will block waiting for a {{.ValType.Name}}.
// This method should be used if you want one goroutine to make requests to many
// different data loaders without blocking until the thunk is called.
func (l *{{.Name}}) LoadThunk(key {{.KeyType.String}}) ({{.ValType.String}}, func() ({{.ValType.String}}, error)) {
	if l.redisConfig != nil {
		// using Redis
			v, err := l.redisConfig.GetFunc(context.Background(), {{.Name}}CacheKeyPrefix+{{ToRedisKey .KeyType.String }})
		if err == nil {
			{{ if eq .KeyType.String "string" }}{{.ValType.String|LoadThunkMarshalType}}
			{{else}}// found in Redis, attempt to return value
			{{.ValType.String|LoadThunkMarshalType}}
			// error unmarshalling, just add to batch{{end}}
		}
		// not found in Redis or error, continue
		l.mu.Lock() // unsafeAddToBatch will unlock
	} else {
		if l.hookExternalCacheGet != nil {
			if v, ok := l.hookExternalCacheGet(key); ok {
				return v, nil
			}
			// not found in external cache, continue
			l.mu.Lock() // unsafeAddToBatch will unlock
		} else {
			l.mu.Lock() // unsafeAddToBatch will unlock
			{{ if not .DisableCacheExpiration }}
			if l.expireAfter <= 0 && len(l.cache) > 0 {
				// not using cache expiration
				if it, ok := l.cache[key]; ok {
					l.mu.Unlock()
					return it, nil
				}
			} else if l.expireAfter > 0 && len(l.cacheExpire) > 0 {
				// using cache expiration
				l.unsafeBatchSet()
				if it, ok := l.cacheExpire[key]; ok {
					if it != nil && !it.expired(l.batch.now) {
						l.mu.Unlock()
						return it.Value, nil
					}
					// cache item has expired, clear from cache
					delete(l.cacheExpire, key)
					if l.hookAfterExpired != nil {
						l.hookAfterExpired(key)
					}
				}
			}
			{{ else }}
			if len(l.cache) > 0 {
				if it, ok := l.cache[key]; ok {
					l.mu.Unlock()
					return it, nil
				}
			}
			{{ end }}
		}
	}
	return l.unsafeAddToBatch(key)
}

// unsafeAddToBatch adds the key to the current batch and returns a thunk to be called later. This method is not thread safe. Expects l.mu.lock() to have been called prior to calling this method.
func (l *{{.Name}}) unsafeAddToBatch(key {{.KeyType.String}}) ({{.ValType.String}}, func() ({{.ValType.String}}, error)) {
	l.unsafeBatchSet()
	batch := l.batch
	pos := batch.keyIndex(l, key)
	l.mu.Unlock()

	return {{.ValType.String|loadThunkMissReturnType}}, func() ({{.ValType.String}}, error) {
		<-batch.done

		// batch has been closed, pull result
		data, err := batch.getResult(pos)
		
		if err == nil && l.redisConfig == nil  {
			// not using Redis, set the cache here, otherwise it'll be done on batch fetch completion
			l.batchResultSet(key, data)
		}

		return data, err
	}
}

// LoadAll fetches many keys at once. It will be broken into appropriate sized
// sub batches depending on how the loader is configured
func (l *{{.Name}}) LoadAll(keys []{{.KeyType}}) ([]{{.ValType.String}}, []error) {
	if len(keys) == 0 {
		return nil, nil
	}
	retVals := make([]{{.ValType.String}}, len(keys))
	thunks := make(map[int]func() ({{.ValType.String}}, error), len(keys))
	errors := make([]error, len(keys))

	if l.redisConfig != nil && l.redisConfig.GetManyFunc != nil {
		// using Redis and GetManyFunc is set
		rKeys := make([]string, len(keys))
		for idx, key := range keys {
			rKeys[idx] = {{.Name}}CacheKeyPrefix + {{ToRedisKey .KeyType.String }}
		}
		vS, errs, err := l.redisConfig.GetManyFunc(context.Background(), rKeys)
		if err != nil {
			// error occurred performing GetMany, add keys to batch to perform fetch instead
			for i, key := range keys {
				if v, thunk := l.unsafeAddToBatch(key); thunk != nil {
					thunks[i] = thunk
				} else {
					retVals[i] = v
				}
			}
			for i, thunk := range thunks {
				retVals[i], errors[i] = thunk()
			}
			return retVals, errors
		} else if len(vS) != len(keys) || len(errs) != len(keys) {
			// return errors for all keys, invalid lengths returned
			for i := range errors {
				errors[i] = Err{{.Name}}GetManyLength
			}
		} else {
			for i, err := range errs {
				if err != nil {
					l.mu.Lock() // unsafeAddToBatch will unlock
					if _, thunk := l.unsafeAddToBatch(keys[i]); thunk != nil {
						thunks[i] = thunk
					}
				} else {
					{{.ValType.String|LoadAllMarshalType}}
				}
			}
		}
	} else {
		// not using Redis or GetManyFunc is not set
		for i, key := range keys {
			if v, thunk :=  l.LoadThunk(key); thunk != nil {
				thunks[i] = thunk
			} else {
				retVals[i] = v
			}
		}
	}
	for i, thunk := range thunks {
		retVals[i], errors[i] = thunk()
	}

	return retVals, errors
}

// LoadAllThunk returns a function that when called will block waiting for a {{.ValType.Name}}s.
// This method should be used if you want one goroutine to make requests to many
// different data loaders without blocking until the thunk is called.
// TODO: Add support for Redis GetManyFunc
func (l *{{.Name}}) LoadAllThunk(keys []{{.KeyType}}) (func() ([]{{.ValType.String}}, []error)) {
	thunks := make(map[int]func() ({{.ValType.String}}, error), len(keys))
	{{.ValType.Name|lcFirst}}s := make([]{{.ValType.String}}, len(keys))
	for i, key := range keys {
		if v, thunk :=  l.LoadThunk(key); thunk != nil {
			thunks[i] = thunk
		} else {
			{{.ValType.Name|lcFirst}}s[i] = v
		}
	}
	return func() ([]{{.ValType.String}}, []error) {
		errors := make([]error, len(keys))
		for i, thunk := range thunks {
			{{.ValType.Name|lcFirst}}s[i], errors[i] = thunk()
		}
		return {{.ValType.Name|lcFirst}}s, errors
	}
}

// redisPrime will set the key value pair in Redis
func (l *{{.Name}}) redisPrime(key {{.KeyType}}, value {{.ValType.String}}) bool {
	if err := l.redisConfig.SetFunc(context.Background(), {{.Name}}CacheKeyPrefix+{{ToRedisKey .KeyType.String }}, value, l.redisConfig.SetTTL); err != nil {
		return false
	} else if l.hookAfterSet != nil {
		l.hookAfterSet(key, value)
	}
	return true
}

// unsafePrime will prime the cache with the given key and value if the key does not exist. This method is not thread safe.
func (l *{{.Name}}) unsafePrime(key {{.KeyType}}, value {{.ValType.String}}, forceReplace bool) bool {
	if l.redisConfig != nil {
		// using Redis
		return l.redisPrime(key, value)
	}
	if l.hookExternalCacheSet != nil {
		{{- if .ValType.IsPtr }}
		// make a copy when writing to the cache, its easy to pass a pointer in from a loop var
		// and end up with the whole cache pointing to the same value.
		cpy := *value
		if err := l.hookExternalCacheSet(key, &cpy); err != nil {
			return false
		}
		{{- else if .ValType.IsSlice }}
		// make a copy when writing to the cache, its easy to pass a pointer in from a loop var
		// and end up with the whole cache pointing to the same value.
		cpy := make({{.ValType.String}}, len(value))
		copy(cpy, value)
		if err := l.hookExternalCacheSet(key, cpy); err != nil {
			return false
		}
		{{- else }}
		if err := l.hookExternalCacheSet(key, value); err != nil {
			return false
		}
		{{- end }}
		if l.hookAfterSet != nil {
			l.hookAfterSet(key, value)
		}
		return true
	}
	var found bool
	{{ if not .DisableCacheExpiration }}
	if l.expireAfter <= 0 {
		// not using cache expiration
	{{ end }}
		if _, found = l.cache[key]; found && forceReplace {
			delete(l.cache, key)
		}
		if !found || forceReplace {
			{{- if .ValType.IsPtr }}
				// make a copy when writing to the cache, its easy to pass a pointer in from a loop var
				// and end up with the whole cache pointing to the same value.
				cpy := *value
				l.unsafeSet(key, &cpy)
			{{- else if .ValType.IsSlice }}
				// make a copy when writing to the cache, its easy to pass a pointer in from a loop var
				// and end up with the whole cache pointing to the same value.
				cpy := make({{.ValType.String}}, len(value))
				copy(cpy, value)
				l.unsafeSet(key, cpy)
			{{- else }}
				l.unsafeSet(key, value)
			{{- end }}
		}
	{{ if not .DisableCacheExpiration }}
	} else {
		// using cache expiration
		if _, found = l.cacheExpire[key]; found && forceReplace  {
			delete(l.cacheExpire, key)
		}
		if !found || forceReplace {
			{{- if .ValType.IsPtr }}
				// make a copy when writing to the cache, its easy to pass a pointer in from a loop var
				// and end up with the whole cache pointing to the same value.
				cpy := *value
				l.unsafeSet(key, &cpy)
			{{- else if .ValType.IsSlice }}
				// make a copy when writing to the cache, its easy to pass a pointer in from a loop var
				// and end up with the whole cache pointing to the same value.
				cpy := make({{.ValType.String}}, len(value))
				copy(cpy, value)
				l.unsafeSet(key, cpy)
			{{- else }}
				l.unsafeSet(key, value)
			{{- end }}
		}
	}
	{{ end }}
	return !found || forceReplace
}

// PrimeManyNoReturn will prime the cache with the given keys and values. Value index is matched to key index. Wraps the PrimeMany and ignores the return values. Helpful if you want to connect up to HookAfterPrimeMany in another dataloader
func (l *{{.Name}}) PrimeManyNoReturn(keys []{{.KeyType}}, values []{{.ValType.String}}) {
	l.PrimeMany(keys, values)
}

// PrimeMany will prime the cache with the given keys and values. Value index is matched to key index.
func (l *{{.Name}}) PrimeMany(keys []{{.KeyType}}, values []{{.ValType.String}}) []bool {
	if len(keys) != len(values) {
		// keys and values must be the same length
		return make([]bool, len(keys))
	}
	ret := make([]bool, len(keys))
	var hookKeys []{{.KeyType}}
	var hookValues []{{.ValType.String}}
	if l.hookAfterPrimeMany != nil {
		hookKeys = make([]{{.KeyType}}, 0, len(keys))
		hookValues = make([]{{.ValType.String}}, 0, len(values))
	}
	if l.redisConfig != nil {
		// using Redis
		if l.redisConfig.SetManyFunc != nil && len(keys) > 1 {
			// SetManyFunc is set and items to prime is >1
			// convert values slice (of {{.ValType.String}}) to interface slice
			vSet := make([]interface{}, len(values))
			for i := range values {
				vSet[i] = values[i]
			}
			{{ if ne .KeyType.String "string" }}// convert keys slice (of {{.KeyType.String}}) to string slice
			kSet := make([]string, len(keys))
			for i, key := range keys {
				kSet[i] = {{.Name}}CacheKeyPrefix + {{ToRedisKey .KeyType.String }}
			}
			// call SetManyFunc with our keys and values
			retErr, err := l.redisConfig.SetManyFunc(context.Background(), kSet, vSet, l.redisConfig.SetTTL)
			{{- else }}// call SetManyFunc with our keys and values
			retErr, err := l.redisConfig.SetManyFunc(context.Background(), keys, vSet, l.redisConfig.SetTTL)
			{{- end }}
			if err == nil {
			 	// set the return values based on each key's error
				for i, err := range retErr {
					ret[i] = err == nil
					if ret[i] {
						// success, call hookAfterSet, hookAfterPrime, and prepare for hookAfterPrimeMany if any are set
						if l.hookAfterSet != nil {
							l.hookAfterSet(keys[i], values[i])
						}
						if l.hookAfterPrimeMany != nil {
							hookKeys = append(hookKeys, keys[i])
							hookValues = append(hookValues, values[i])
						} else if l.hookAfterPrime != nil {
							l.hookAfterPrime(keys[i], values[i])
						}
					}
				}
				// call hookAfterPrimeMany if set
				if l.hookAfterPrimeMany != nil {
					l.hookAfterPrimeMany(hookKeys, hookValues)
				}
			}
		} else {
			// fallback to using redisPrime (one at a time)
			for i, key := range keys {
				ret[i] = l.redisPrime(key, values[i])
				if ret[i] {
					// success, call hookAfterPrime and prepare for hookAfterPrimeMany if any are set. redisPrime will handle the call to hookAfterSet
					if l.hookAfterPrimeMany != nil {
						hookKeys = append(hookKeys, keys[i])
						hookValues = append(hookValues, values[i])
					} else if l.hookAfterPrime != nil {
						l.hookAfterPrime(keys[i], values[i])
					}
				}
			}
			// call hookAfterPrimeMany if set
			if l.hookAfterPrimeMany != nil {
				l.hookAfterPrimeMany(hookKeys, hookValues)
			}
		}
	} else {
		l.mu.Lock()
		for i, key := range keys {
			ret[i] = l.unsafePrime(key, values[i], false)
			if ret[i] {
				// success, call hookAfterPrime and prepare for hookAfterPrimeMany if any are set. unsafePrime will handle the call to hookAfterSet
				if l.hookAfterPrimeMany != nil {
					hookKeys = append(hookKeys, keys[i])
					hookValues = append(hookValues, values[i])
				} else if l.hookAfterPrime != nil {
					l.hookAfterPrime(keys[i], values[i])
				}
			}
		}
		l.mu.Unlock()
		// call hookAfterPrimeMany if set
		if l.hookAfterPrimeMany != nil {
			l.hookAfterPrimeMany(hookKeys, hookValues)
		}
	}
	return ret
}

// Prime the cache with the provided key and value. If the key already exists, no change is made
// and false is returned.
// (To forcefully prime the cache, clear the key first with loader.clear(key).prime(key, value).)
func (l *{{.Name}}) Prime(key {{.KeyType}}, value {{.ValType.String}}) bool {
	if l.redisConfig != nil {
		// using Redis
		b := l.redisPrime(key, value)
		if l.hookAfterPrime != nil {
			l.hookAfterPrime(key, value)
		}
		return b
	} else {
		l.mu.Lock()
		found := l.unsafePrime(key, value, false)
		l.mu.Unlock()
		if l.hookAfterPrime != nil {
			l.hookAfterPrime(key, value)
		}
		return found
	}
}

// ForcePrime the cache with the provided key and value. If the key already exists, value is replaced
// (This removes the requirement to clear the key first with loader.clear(key).prime(key, value))
func (l *{{.Name}}) ForcePrime(key {{.KeyType}}, value {{.ValType.String}}) {
	l.batchResultSet(key, value)
	if l.hookAfterPrime != nil {
		l.hookAfterPrime(key, value)
	}
}

// Clear the value at key from the cache, if it exists
func (l *{{.Name}}) Clear(key {{.KeyType}}) {
	if l.redisConfig != nil {
		// using Redis
		l.redisConfig.DeleteFunc(context.Background(), {{.Name}}CacheKeyPrefix+{{ToRedisKey .KeyType.String }})
		if l.hookAfterClear != nil {
			l.hookAfterClear(key)
		}
		return
	}
	if l.hookExternalCacheDelete != nil {
		l.hookExternalCacheDelete(key)
		if l.hookAfterClear != nil {
			l.hookAfterClear(key)
		}
		return 
	}
	{{ if not .DisableCacheExpiration }}
	if l.expireAfter <= 0 {
		// not using cache expiration
	{{ end }}
		l.mu.Lock()
		delete(l.cache, key)
		l.mu.Unlock()
	{{ if not .DisableCacheExpiration }}
	} else {
		// using cache expiration
		l.mu.Lock()
		delete(l.cacheExpire, key)
		l.mu.Unlock()
	}
	{{ end }}
	if l.hookAfterClear != nil {
		l.hookAfterClear(key)
	}
}

// ClearAllPrefix clears all values from the cache that match the given prefix (after the cache key prefix if using Redis) Prefix filtering is only used when using Redis and GetKeysFunc is defined or your key type is a string, otherwise all keys are cleared.
func (l *{{.Name}}) ClearAllPrefix(prefix string) {
	if l.redisConfig != nil {
		// using Redis
		if l.redisConfig.GetKeysFunc != nil {
			// get all keys from Redis
			keys, _ := l.redisConfig.GetKeysFunc(context.Background(), {{.Name}}CacheKeyPrefix+prefix+"*")
			// delete all these keys from Redis
			if l.redisConfig.DeleteManyFunc != nil {
				l.redisConfig.DeleteManyFunc(context.Background(), keys)
			} else {
				for _, key := range keys {
					l.redisConfig.DeleteFunc(context.Background(), key)
				}
			}
			if l.hookAfterClearAllPrefix != nil {
				l.hookAfterClearAllPrefix(prefix)
			}
			if l.hookAfterClearAll != nil {
				l.hookAfterClearAll()
			}
		}
		return
	}
	if l.hookExternalCacheClearAll != nil {
		l.hookExternalCacheClearAll()
		if l.hookAfterClearAllPrefix != nil {
				l.hookAfterClearAllPrefix(prefix)
		}
		if l.hookAfterClearAll != nil {
			l.hookAfterClearAll()
		}
		return 
	}
	{{ if not .DisableCacheExpiration }}
	if l.expireAfter <= 0 {
		// not using cache expiration
	{{ end}}
		l.mu.Lock()
		{{ if eq .KeyType.String "string" }}
		if prefix != "" {
			// clear all keys that match the prefix
			for key := range l.cache {
				if strings.HasPrefix(key, prefix) {
					delete(l.cache, key)
				}
			}
		} else {
			l.cache = make(map[{{.KeyType}}]{{.ValType.String}}, l.maxBatch)
		}
		{{ else }}
		l.cache = make(map[{{.KeyType}}]{{.ValType.String}}, l.maxBatch)
		{{ end }}
		l.mu.Unlock()
	
	{{ if not .DisableCacheExpiration }}
	} else {
		// using cache expiration
		l.mu.Lock()
		{{ if eq .KeyType.String "string" }}
		if prefix != "" {
			// clear all keys that match the prefix
			for key := range l.cacheExpire {
				if strings.HasPrefix(key, prefix) {
					delete(l.cacheExpire, key)
				}
			}
		} else {
			l.cacheExpire = make(map[{{.KeyType}}]*{{.Name}}CacheItem, l.maxBatch)
		}
		{{ else }}
		l.cacheExpire = make(map[{{.KeyType}}]*{{.Name}}CacheItem, l.maxBatch)
		{{ end }}
		l.mu.Unlock()
	}
	{{ end }}
	if l.hookAfterClearAllPrefix != nil {
		l.hookAfterClearAllPrefix(prefix)
	}
	if l.hookAfterClearAll != nil {
		l.hookAfterClearAll()
	}
}

// ClearAll clears all values from the cache
func (l *{{.Name}}) ClearAll() {
	l.ClearAllPrefix("")
}

{{ if not .DisableCacheExpiration }}
// ClearExpired clears all expired values from the cache if cache expiration is being used
func (l *{{.Name}}) ClearExpired() {
	if l.redisConfig != nil {
		// using Redis. Nothing to do, TTL will handle this
		return
	}
	if l.expireAfter > 0 {
		// using cache expiration
		tNow := time.Now().UnixNano()
		l.mu.Lock()
		for cacheKey, cacheItem := range l.cacheExpire {
			if cacheItem != nil && tNow > cacheItem.Expires {
				// value has expired
				delete(l.cacheExpire, cacheKey)
				if l.hookAfterExpired != nil {
					l.hookAfterExpired(cacheKey)
				}
			}
		}
		l.mu.Unlock()
	}
}

{{ end }}
// unsafeSet will set the key to value without any locks or checks. This method is not thread safe.
func (l *{{.Name}}) unsafeSet(key {{.KeyType}}, value {{.ValType.String}}) {
	if l.redisConfig != nil {
		// using Redis
		l.redisPrime(key, value)
		return
	}
	if l.hookExternalCacheSet != nil {
		l.hookExternalCacheSet(key, value)
		if l.hookAfterSet != nil {
			l.hookAfterSet(key, value)
		}
		return
	}
	{{ if not .DisableCacheExpiration }}
	if l.expireAfter <= 0 {
		// not using cache expiration
	{{ end }}
		if l.cache == nil {
			l.cache = make(map[{{.KeyType}}]{{.ValType.String}}, l.maxBatch)
		}
		l.cache[key] = value
	{{ if not .DisableCacheExpiration }}
	} else {
		// using cache expiration
		if l.cacheExpire == nil {
			l.cacheExpire = make(map[{{.KeyType}}]*{{.Name}}CacheItem, l.maxBatch)
		}
		l.cacheExpire[key] = &{{.Name}}CacheItem{Expires: time.Now().UnixNano()+l.expireAfter, Value: value}
	}
	{{ end }}
	if l.hookAfterSet != nil {
		l.hookAfterSet(key, value)
	}
}

// keyIndex will return the location of the key in the batch, if its not found
// it will add the key to the batch
func (b *{{.Name|lcFirst}}Batch) keyIndex(l *{{.Name}}, key {{.KeyType}}) int {
	b.reqCount++
	if i, ok := b.keysMap[key]; ok {
		return i
	}

	pos := len(b.keysMap)
	b.keysMap[key] = pos
	b.keys = append(b.keys, key)
	if pos == 0 {
		go b.startTimer(l)
	}

	// have we reached out max batch size?
	if l.maxBatch != 0 && pos >= l.maxBatch-1 {
		if !b.closing {
			// not already closing, close the batch and call end
			b.closing = true
			l.batch = nil
			go b.end(l)
		}
	}

	return pos
}

// startTimer will wait the desired wait time before sending the batch unless another batch limit had been reached
func (b *{{.Name|lcFirst}}Batch) startTimer(l *{{.Name}}) {
	time.Sleep(l.wait)
	l.mu.Lock()

	// we must have hit a batch limit and are already finalizing this batch
	if b.closing {
		l.mu.Unlock()
		return
	}

	l.batch = nil
	l.mu.Unlock()

	b.end(l)
}

// end calls fetch and closes the done channel to unblock all thunks
func (b *{{.Name|lcFirst}}Batch) end(l *{{.Name}}) {
	if l.hookBeforeFetch != nil {
		l.hookBeforeFetch(b.keys, "{{.Name}}")
	}
	b.data, b.errors = l.fetch(b.keys)
	if l.redisConfig != nil && len(b.errors)  > 0 {
		// using Redis, set the cache here for all results without an error
		if len(b.errors) > 1 && l.redisConfig.SetManyFunc != nil {
			// multiple keys, build key/value set of non errors
			kSet := make([]string, 0, len(b.keys))
			vSet := make([]interface{}, 0, len(b.keys))
			{{ if ne .KeyType.String "string" }}for i, key := range b.keys {
				if b.errors[i] == nil {
					// convert keys slice (of {{.KeyType.String}}) to string slice
					kSet = append(kSet, {{.Name}}CacheKeyPrefix + {{ToRedisKey .KeyType.String }})
			{{- else }}for i := range b.keys {
				if b.errors[i] == nil {
					kSet = append(kSet, {{.Name}}CacheKeyPrefix + b.keys[i])
					{{- end }}
					vSet = append(vSet, b.data[i])
				}
			}
			if len(kSet) > 0 {
				// call SetManyFunc with our keys and values
				l.redisConfig.SetManyFunc(context.Background(), kSet, vSet, l.redisConfig.SetTTL)
			}
		} else {
			// only one key or SetManyFunc not set, set the value(s) if no error using batchResultSet
			for i, key := range b.keys {
				if b.errors[i] == nil {
					l.batchResultSet(key, b.data[i])
				}
			}
		}
	}
	if l.hookAfterFetch != nil {
		l.hookAfterFetch(b.keys, "{{.Name}}")
	}
	// close done channel to signal all thunks to unblock
	close(b.done)
}

// getResult will return the result for the given position from the batch
func (b *{{.Name|lcFirst}}Batch) getResult(pos int) ({{.ValType.String}}, error) {
	var data {{.ValType.String}}
	b.lock.Lock()
	if pos < len(b.data) {
		data = b.data[pos]
	}

	var err error
	// its convenient to be able to return a single error for everything
	if len(b.errors) == 1 {
		err = b.errors[0]
	} else if b.errors != nil {
		err = b.errors[pos]
	}

	// check if all thunks have checked in and if so, return batch to pool
	b.checkedIn++
	if b.checkedIn >= b.reqCount {
		// reset
		b.reqCount = 0
		b.checkedIn = 0
		clear(b.keysMap)
		clear(b.keys)
		b.lock.Unlock()
		// all thunks have checked in, return batch to pool for re-use
		b.loader.batchPool.Put(b)
	} else {
		b.lock.Unlock()
	}

	// return data and error
	return data, err
}

// Marshal{{.Name}}ToString is a helper method to marshal a {{.Name}} to a string
func (l *{{.Name}}) Marshal{{.Name}}ToString(v {{.KeyType.String}}) string {
	ret, _ := l.redisConfig.ObjMarshal(v)
	return string(ret)
}
`))
